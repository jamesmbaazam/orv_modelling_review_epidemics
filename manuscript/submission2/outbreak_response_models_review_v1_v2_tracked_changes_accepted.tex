% Template for PLoS
% Version 3.5 March 2018
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file 
% and leave only the final text of your manuscript. 
% PLOS recommends the use of latexdiff to track changes during review, as this will help to maintain a clean tex file.
% Visit https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that 
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first \cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission. 
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig" instead of "Figure".
% See http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation in the math environment.  For example, x$^2$ is incorrect; this should be formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example, CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please group using {}.  For example, change "[U(D,E,\gamma)]^2" to "{[U(D,E,\gamma)]}^2". 
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8x]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% \cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to \cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}


% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother



% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
%\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
%\setlength{\headheight}{27.023pt}
%\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\today}

%% Include all macros below

\newcommand{\lorem}{{\bf LOREM}}
\newcommand{\ipsum}{{\bf IPSUM}}

%% END MACROS SECTION



\begin{document}
\vspace*{0.2in}

% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Modelling outbreak response impact in human vaccine-preventable diseases: A systematic review of differences in practices between collaboration types before COVID19}
}
\newline
\\
James M. Azam\textsuperscript{1, 2*},
Xiaoxi Pang\textsuperscript{3},
Elisha B. Are\textsuperscript{2, 4},
Juliet R.C. Pulliam\textsuperscript{2},
Matthew J. Ferrari\textsuperscript{5}
\\
\bigskip
\textbf{1} Department of Infectious Disease Epidemiology, London School of Hygiene and Tropical Medicine, London, United Kingdom
\\
\textbf{2} DSI-NRF Centre of Excellence in Epidemiological Modelling and Analysis (SACEMA), Stellenbosch University, Stellenbosch 7600, South Africa
\\
\textbf{3} Department of Mathematics, The University of Manchester, Manchester, United Kingdom
\\
\textbf{4} Department of Mathematics, Simon Fraser University, Burnaby, BC, Canada
\\
\textbf{5} Center for Infectious Disease Dynamics, Department of Biology, The Pennsylvania
State University, University Park, Pennsylvania, USA
\\
\bigskip

* james.azam@lshtm.ac.uk


\end{flushleft}
\section*{Abstract}
\subsection*{Background}
Outbreak response modelling often involves collaboration among academics, and experts from governmental and non-governmental organisations. We conducted a systematic review of modelling studies on human vaccine-preventable disease (VPD) outbreaks to identify patterns in modelling practices between two collaboration types. We complemented this with a mini comparison of foot-and-mouth disease (FMD), a veterinary disease that is controllable by vaccination.   
\subsection*{Methods}
We searched three databases for modelling studies that assessed the impact of an outbreak response. We extracted data on author affiliation type (academic institution, governmental, and non-governmental organizations), location studied, and whether at least one author was affiliated to the studied location. We also extracted the outcomes and interventions studied, and model characteristics. Included studies were grouped into two collaboration types: purely academic (papers with only academic affiliations), and mixed (all other combinations) to help investigate differences in modelling patterns between collaboration types in the human disease literature and overall differences with FMD collaboration practices. 
\subsection*{Results}
Human VPDs formed 227 of 252 included studies. Purely academic collaborations dominated the human disease studies (56\%). Notably, mixed collaborations increased in the last seven years (2013 - 2019). Most studies had an author affiliated to an institution in the country studied (75.2\%) but this was more likely among the mixed collaborations. Contrasted to the human VPDs, mixed collaborations dominated the FMD literature (56\%). Furthermore, FMD studies more often had an author with an affiliation to the country studied (92\%) and used complex model design, including stochasticity, and model parametrization and validation. 
\subsection*{Conclusion}
The increase in mixed collaboration studies over the past seven years could suggest an increase in the uptake of modelling for outbreak response decision-making. We encourage more mixed collaborations between academic and non-academic institutions and the involvement of locally affiliated authors to help ensure that the studies suit local contexts.

\subsection*{Keywords}
Infectious disease dynamics; outbreak response modelling

\section*{Highlights}
\begin{enumerate}
	\item We explored differences in collaborative modelling practices in the human-vaccine preventable disease outbreak response literature.
	\item Collaborations were grouped into purely academic and mixed.
	\item The collaboration types differed in terms of their model choices and practices.
	\item Purely academic collaborations dominated the human vaccine-preventable diseases literature.
	\item Mixed collaborations were more likely to involve local experts and use complex methods.
\end{enumerate}

\linenumbers

\section*{Introduction}
Successful outbreak response to infectious diseases is often the result of a highly collaborative process~\cite{Sigfrid2020}. Decision-making during outbreak response usually requires collaborations between academic and field experts, including governmental and Non-Governmental Organizations (NGOs)~\cite{Kretzschmar2020,Kerkhove2012,Okiror2021,Whitty2014,Sigfrid2020}. These collaborations ensure that important perspectives from both research and operations/implementation are accounted for in the decision-making process. 

Outbreak response decision-making often requires adaptations to the affected location ~\cite{Whitty2014,Heesterbeek2015,Sigfrid2020}. The interventions and decisions are usually driven by data/evidence, information, and experiences from the past or in real-time, either locally or from similar phenomena elsewhere ~\cite{Abramowitz2015,Kerkhove2012}. Furthermore, involving local experts in the design of interventions has been found to boost the success of outbreak response efforts ~\cite{Sigfrid2020}. Consequently, outbreak response should ideally involve at least one local expert to provide more context~\cite{Sigfrid2020}.  

Mathematical modelling can support outbreak response decision-making~\cite{Lofgren2015}. Modelling is a proven tool for revealing insights about the extent of disease spread, and impact of interventions, and providing recommendations for decision-making during outbreaks~\cite{Kretzschmar2020,Whitty2014,Lofgren2015}. Insights from mathematical modelling, though often useful, only form part of the larger context (socio-economic, political, and so forth) to be considered during an outbreak, making it difficult to determine the extent to which it contributes to outbreak response decision-making ~\cite{Kretzschmar2020,Kerkhove2012}. One way to help ensure that modelling contributes to decision-making is the conduct of interdisciplinary research  --- that is, research conducted by authors with diverse scientific backgrounds --- between model developers and decision-makers.

The link between interdisciplinarity in scientific research and research impact, for example, number of citations has been well-researched~\cite{Abramo2017,Wagner2011}. However, few studies have investigated the impact of interdisciplinary collaborations on the conduct of scientific research. One such study investigated the impact of interdisciplinarity on the scientific validity of the methods used in a selection of papers that applied machine learning on topics in biology or medicine~\cite{Littmann2020}. The study found that the methods used in the reviewed studies differed according to the nature of the scientific backgrounds of the authors who conducted the research. 


Our preliminary search of the literature did not reveal any systematic reviews investigating differences in research practices among collaborations in the outbreak response modelling literature. We, therefore, conducted this systematic review of outbreak response modelling studies of human vaccine-preventable diseases with the aim to explore the time and geographic patterns in the collaboration landscape, and to investigate differences in model choices and modelling practices. We categorised the collaboration landscape into two types: (1) purely academic collaborations: papers with all authors affiliated to academic institutions, and (2) mixed collaborations, that is, papers with authors affiliated to a mixture of academic, government and NGO affiliations. Using this classification, we investigated differences in the choice of model structure, dynamics, individual and spatial heterogeneity, and modelling methods such as model parametrization, validation, sensitivity analysis, the use of data and provision of data and code for reproducibility. 

We sought to answer the following questions with respect to the two collaboration types in the human disease outbreak response modelling literature: (1) How are the studies distributed in time (years) and geographic locations, (2) Is there a difference in the practice of including local experts in modelling exercises? (3) Do the choice of model characteristics (structure and dynamics) and modelling methods/approaches (model parametrization and validation, outcomes of interest, sensitivity analyses, use of data, and code availability) differ between the collaboration types?    

Even though this review is about human VPDs, we acknowledge and include the modelling work done in the veterinary literature and in particular, for foot-and-mouth disease (FMD). Specifically, the outbreak response modelling effort resulting from the 2001 (FMD) outbreak in the United Kingdom has been a foundational example of the application of mathematical modelling to decision-making. Subsequent work based on this outbreak has been instrumental in the development of FMD outbreak intervention strategies around the world. We, therefore, include some relevant FMD references for comparison. Essentially, in this review, we study the differences in terms of collaboration types in the human disease modelling literature, and compare our observations to some parallel results from the FMD modelling literature. This is useful for investigating any differences in approaches and practices between the human and livestock literature and opens up opportunities for future work. 

   The following were the objectives of the systematic review:
\begin{enumerate}
	\item To characterise the nature of collaboration types through geographic space and time,
	\item To investigate if there were differences between the collaboration types regarding the inclusion of local experts,
	\item To report differences between the collaboration types in terms of the choice of model structure, dynamics and heterogeneity, and
	\item To investigate and report differences in modelling methods/approaches (model parametrization, validation, sensitivity analyses, code availability, and so forth) between collaboration types.
	\item To report on miscellaneous interesting aspects captured by each study including the disease, interventions, and outcomes studied.
\end{enumerate}


\section*{Materials and methods}
We followed the 2020 Preferred Reporting Items for Systematic Reviews and Meta-analyses statement (PRISMA 2020)  to conduct this systematic review \cite{Page2021}.

\subsection*{Eligibility criteria}
The following definitions were used in the determining study eligibility:

\begin{itemize}
	\item ``Outbreak'': a new and sudden rise in the number of cases of a disease in a population, which when left uncontrolled, could lead to large scale geographic spread, AND 
	\item ``Outbreak response'': an intervention directly triggered by the outbreak of an infectious disease, AND
	\item ``Mechanistic models'': mathematical models that use an equation or system of equations to capture the biological mechanisms driving the transmission dynamics of the infectious disease at the level of an individual or population \cite{Lessler2016a,Reiner2013}, AND
	\item ``Outbreak intervention assessment'': a mechanistic model-based evaluation of the impact of an outbreak response intervention.
\end{itemize}

We included studies that used a mechanistic model to investigate the impact of interventions triggered by the outbreak of any of the human vaccine-preventable diseases listed by the World Health Organization as of 2019 (Table 1 in \nameref{S1_File}). Aside from the WHO list, we also included Ebola because at the time of conducting this review, a vaccine had been approved for outbreak response purposes. We also included foot-and-mouth disease for comparison as a candidate veterinary disease that is manageable by vaccination and has been well modelled in the past. 


Studies were considered unique even if they had a duplicated author list or a slight variation in the author list, probably representing the same modelling group, so far as the content of the paper was different. 


We excluded studies that satisfied at least one of the following criteria: 

\begin{itemize}
	\item Study used a model that is not mechanistic,
	\item Study is not about an outbreak as defined above,
	\item Disease studied is not a human vaccine-preventable disease (Table 1 in \nameref{S1_File}), Ebola or foot-and-mouth disease,
	\item Study's objective is not to evaluate the impact of an intervention mounted in response to an outbreak, or
	\item Study is not published in English.
\end{itemize}

\subsection*{Information sources}
On January 15, 2020, we searched Scopus, PubMed, and Web of Science for eligible records. We searched each database from its earliest date of coverage through January 15, 2020. 

\subsection*{Search strategy}
We constructed and validated search strings specific to each database. To validate the search strings, we first ran them in the specific database's search engine and obtained a database of records. We then searched the database for well-known papers that fit the criteria for included studies. We did this for each disease on our list. 

The search strings were constructed by all five reviewers (JMA, XP, EBA, MJF, and JRCP) and in consultation with the Faculty of Science Librarian of Stellenbosch University to reflect three main topics and their synonyms, that is, ``outbreak'', ``intervention'', and ``mechanistic model''. 

The following are the search strings per database. 

\textbf{Scopus (Title, abstract, keywords search)}:

( TITLE-ABS-KEY ( epidemic  OR  outbreak  OR  emergency  OR  reactive  OR  crisis ) )  AND  ( TITLE-ABS-KEY ( respon*  OR  manage*  OR  control  OR  interven*  OR  strateg* ) )  AND  ( TITLE-ABS-KEY ( stochastic  OR  transmission  OR  computational  OR  mathematical  OR  mechanistic  OR  statistical  OR  simulation  OR  "In silico"  OR  dynamic* ) )  AND  ( TITLE-ABS-KEY ( model* ) )  AND  ( ( TITLE-ABS-KEY ( cholera  OR  dengue  OR  diphtheria  OR  ebola  OR  "Foot-and-mouth"  OR  "foot and mouth"  OR  fmd  OR  "Hepatitis A"  OR  "Hepatitis B"  OR  "Hepatitis E"  OR  "Haemophilus influenzae type b"  OR  hib  OR  "Human papillomavirus"  OR  hpv  OR  influenza ) )  OR  ( TITLE-ABS-KEY ( "Japanese encephalitis"  OR  malaria  OR  measles  OR  "Meningococcal meningitis"  OR  mumps  OR  pertussis  OR  "Whooping cough"  OR  "Pneumococcal disease"  OR  poliomyelitis  OR  polio  OR  rabies  OR  rotavirus  OR  rubella ) )  OR  ( TITLE-ABS-KEY ( tetanus  OR  "Tick-borne encephalitis"  OR  tuberculosis  OR  typhoid  OR  varicella  OR  chickenpox  OR  "Yellow Fever"  OR  "vaccine-preventable" ) ) )

\textbf{PubMed (Title and abstract search)}:

Search ((((((Epidemic OR Outbreak OR Emergency OR Reactive OR Crisis))) AND ((Response OR Management OR Control OR Intervention OR Strategies))) AND ((Stochastic OR Transmission OR Computational OR Mathematical OR Mechanistic OR Statistical OR Simulation OR "In silico" OR Dynamic*))) AND model*) AND ((Cholera OR Dengue OR Diphtheria OR Ebola OR "Foot-and-mouth" OR "foot and mouth" OR FMD OR "Hepatitis A" OR "Hepatitis B" OR "Hepatitis E" OR "Haemophilus influenzae type b" OR Hib OR "Human papillomavirus" OR HPV OR Influenza OR "Japanese encephalitis" OR Malaria OR Measles OR "Meningococcal meningitis" OR Mumps OR Pertussis OR "Whooping cough" OR "Pneumococcal disease" OR Poliomyelitis OR Polio OR Rabies OR Rotavirus OR Rubella OR Tetanus OR "Tick-borne encephalitis" OR Tuberculosis OR Typhoid OR Varicella OR Chickenpox OR "Yellow Fever" OR "vaccine-preventable"))

\textbf{Web of Science (Topic search)}:

TOPIC: (Epidemic OR Outbreak OR Emergency OR Reactive OR Crisis) AND TOPIC: (Respon* OR  Manage*  OR  Control  OR  Interven*  OR  Strateg*)) AND TOPIC: (Stochastic OR Transmission OR Computational OR Mathematical OR Mechanistic OR Statistical OR Simulation OR In silico OR Dynamic*) AND TOPIC: (model*) AND TOPIC: (Cholera OR Dengue OR Diphtheria OR Ebola OR "Foot-and-mouth" OR "foot and mouth" OR FMD OR "Hepatitis A" OR "Hepatitis B" OR "Hepatitis E" OR "Haemophilus influenzae type b" OR Hib OR "Human papillomavirus" OR HPV OR Influenza OR "Japanese encephalitis" OR Malaria OR Measles OR "Meningococcal meningitis" OR Mumps OR Pertussis OR "Whooping cough" OR "Pneumococcal disease" OR Poliomyelitis OR Polio OR Rabies OR Rotavirus OR Rubella OR Tetanus OR "Tick-borne encephalitis" OR Tuberculosis OR Typhoid OR Varicella OR Chickenpox OR "Yellow Fever" OR "vaccine-preventable")


\subsection*{Study selection}
We used Endnote version X7.8 and Rayyan web application (\url{https://www.rayyan.ai/}) to combine the results from the three databases and to identify and remove duplicate records. The unique records were exported into Rayyan web application, where they were screened in two stages by three reviewers (JMA, XP, and EBA). 

Stage one screening involved excluding studies based on their title and abstract, using the questionnaire that follows. The reviewers only used the information provided in the title and abstract of each study to decide whether it was eligible for inclusion (``Include''), not eligible (``Exclude''), or likely to be included (``Maybe''). The ``Include'' and ``Maybe'' category of studies further went through stage two screening described ahead, which was more stringent. 

\subsubsection*{Questionnaire for title and abstract screening (Stage 1)}
\begin{enumerate}
	\item	Is this article written in English?
	\begin{itemize}
		\item 	No: Exclude. Reason: Not English
	\end{itemize}
	\item 	Does the title of this article fit the scope of this review?
	\begin{itemize}
		\item 	No: Exclude. Reason: Title out of scope
	\end{itemize}
	\item	Does the topic of the abstract fit the scope of this review?
	\begin{itemize}
		\item 	No: Exclude. Reason: Topic out of scope
	\end{itemize}
	\item Is this study entirely a review (literature review, systematic review, scoping review, not indicated)? 
	\begin{itemize}
		\item 	Yes: Exclude. Reason: Review
	\end{itemize}
	\item Is any part of this study about an outbreak that happened in the past, was ongoing at the time of the study, or a hypothetical one, including one that could happen in the future? We define an outbreak as a new and sudden rise in the number of cases of a disease in a population, which when left uncontrolled, could lead to large scale geographic spread.
	\begin{itemize}
		\item 	No: Exclude. Reason: Not an outbreak
	\end{itemize}
	\item Is any part of this study about a human infectious disease (Table 1 in \nameref{S1_File}), Ebola or foot-and-mouth disease in livestock?
	\begin{itemize}
		\item 	No: Exclude. Reason: Disease not in scope
	\end{itemize}
	\item Does this study assess the impact – epidemiological or operational - of a real or hypothetical intervention that was mounted or could potentially be mounted in response to an outbreak of the disease in question? Note that we define an assessment as an evaluation of either the absolute or relative impact of an intervention on one of several outcomes including number/proportion of population reached with the intervention (coverage), and a change in size - number of people, duration, spatial - of the outbreak.
	\begin{itemize}
		\item 	No: Exclude. Reason: Not an outbreak intervention assessment
		\item 	Maybe. Reason: Intervention details unclear
	\end{itemize}
	\item Does this study solely use static methods for evaluating the intervention? Static methods include surveys, regression methods, descriptive, and exploratory statistical methods.
	\begin{itemize}
		\item 	No: Exclude. Reason: Not a model
	\end{itemize}
	\item Does this study use any kind of equation, system of equations, or computer simulation to capture the disease’s transmission process or natural history over time?
	\begin{itemize}
		\item 	No: Exclude. Reason: Model not mechanistic
		\item 	Maybe. Reason: Likely a model
	\end{itemize}
\end{enumerate}

Stage one was first piloted with all three reviewers screening the same 50 studies using Rayyan in ``blind mode''. This was so that the reviewers could not see each other's screening decisions (inclusion/exclusion/maybe). After the pilot screening, the results were compared and any inclusion/exclusion conflicts were discussed and resolved. The pilot phase ensured that all the reviewers were using a consistent screening approach. The remaining studies were then screened in duplicate and all conflicting decisions were resolved at the end through discussions among the reviewers. 

Stage 2 involved screening the included studies from stage 1, using their full text, in duplicate and with the following questionnaire.

\subsubsection*{Questionnaire for full text screening (Stage 2)}
\begin{enumerate}
	\item Is this article written in English? (This was necessary because some articles could have English abstracts but non-English full text)
	\begin{itemize}
		\item 	If no, exclude. Reason: Not English	
	\end{itemize}
	\item Is this article a report, commentary or any kind of non-quantitative report?
	\begin{itemize}
		\item 	If yes, exclude. Reason: Article type out of scope
	\end{itemize}
	\item Is the full text readily available?
	\begin{itemize}
		\item 	If no, mark as Maybe. Reason: Full text not available	
	\end{itemize}
	\item Is this study entirely a review (literature review, systematic review, scoping review, not indicated)? 
	\begin{itemize}
		\item 	If yes, exclude. Reason: Review
	\end{itemize}
	\item Is the study or a part of it about an outbreak, real or hypothetical?
	\begin{itemize}
		\item 	If no, exclude. Reason: Not an outbreak
	\end{itemize}
	\item Is the disease a human vaccine-preventable disease (Table 1 in \nameref{S1_File}), Ebola, or foot-and-mouth disease? 
	\begin{itemize}
		\item 	If no, exclude. Reason: Not a listed disease
	\end{itemize}
	\item Does this study solely use static methods for evaluating the intervention? Static methods include surveys, regression methods, descriptive, exploratory statistical methods.
	\begin{itemize}
		\item 	If no, exclude. Reason: Static model or method
	\end{itemize}
	\item Does this study use any kind of equation, system of equations, or computer simulation to capture the disease’s transmission process in a dynamic way?
	\begin{itemize}
		\item 	If no, exclude. Reason: Model not mechanistic
		\item 	If unclear, maybe. Reason: Likely a model
	\end{itemize}
	\item Is the model about within-host dynamics?
	\begin{itemize}
		\item 	If yes, exclude. Reason: Within-host model
	\end{itemize}
	\item Does this study attempt to assess the impact – epidemiological or operational - of a real or hypothetical intervention that was mounted or could potentially be mounted in response to an outbreak of the disease in question? We define an assessment as an evaluation of either the absolute or relative impact of an intervention on one of several outcomes including number/proportion of population reached with the intervention (coverage), and a change in size - number of people, duration, spatial - of the outbreak.
	\begin{itemize}
		\item 	If no, exclude. Reason: Not an outbreak intervention assessment
		\item 	If unclear, maybe. Label: Intervention details unclear
	\end{itemize}
\end{enumerate}

\subsection*{Data extraction}
To extract the data from the studies, we used the data extraction questionnaire implemented with the KoboToolbox web application (Section 3 in \nameref{S1_File}). The questionnaire was first piloted with $10$ papers among the three reviewers, who worked in duplicate. All conflicts in terms of extracted data were resolved through discussion and mutual agreement. 

Following the pilot phase, the full list of included studies was shared among three reviewers (JMA, XP, and EBA), who extracted the relevant data independently. The extracted data was cross-checked by one reviewer (JMA). When a discrepancy was found in the extracted data, the reviewer referred to the original paper and resolved the conflict.  

From each paper, we extracted data on the type of publication (original research, preprint, and so forth), author affiliation type (academic/government/non-governmental), country/setting studied, whether at least one author affiliation was situated in the country studied, disease studied, study objectives (retrospective/prospective impact assessment, timing of the modelling practice with respect to the outbreak (retrospective/prospective/real-time), interventions studied, and whether vaccination was the most impactful intervention when compared as a single intervention (yes/no/inconclusive). A full list of the extracted data items are provided (Section 2 in \nameref{S1_File}).  

From each model described in the methods section, we extracted data on the representation of individuals (compartmental vs individual-based), whether spatial structure was represented (yes/no), model structure (deterministic vs stochastic), model parametrization, and validation. We also extracted a predefined list of outcomes (final epidemic size, attack rate, cases averted, ad a host of others) measured with the models. If the outcome measured was not on the pre-defined list, we collected it separately as free text for further analysis. We collected data on whether the studies included sensitivity analysis or not. This was to understand how uncertainties in the model inputs were dealt with.  We collected data on whether the studies used observed data, that is, excluding simulated data, and whether the data was openly accessible. Lastly, we noted whether the code used for the analysis was openly available. In this regard, we classified code that was only available upon request as not available because of the barrier to access that this approach often introduces.



\subsection*{Data analysis and synthesis}
To understand how the papers were distributed in terms of author affiliations, we first tallied the unique combinations of author affiliation types. We then grouped the author affiliations into the following two collaboration types and performed all further analyses by stratifying the variable(s) of interest by them:

\begin{enumerate}
	\item \textit{Purely academic:} papers with only academic author affiliations (academics collaborating with other academics), 
	\item \textit{Mixed:} papers with a mixture of academic, government and NGO affiliations. This collaboration type also included papers with only government or only NGO affiliations. 
\end{enumerate}

We first explored the trend in aggregated publications during 1970-2019 by counting the number of publications in each year irrespective of collaboration type. 

To explore how the publications changed in time with respect to the collaboration types, we tallied the number of publications and relative proportion (mixed versus purely academic collaboration) of studies per year. We lumped together the publications from 1970 to 2005 due to the small numbers. 

To study how the papers were distributed in terms of geographic locations, we split the studies into those that studied actual versus hypothetical locations and used the subset of studies about actual locations to rank the topmost studied locations (country and continent) by frequency. 

We also investigated how connected the authors were to the locations studied. Here, we only considered studies on geographic scales up to actual countries and not larger. All studies about locations larger than a country were dropped from this part of the analysis. We tallied, in terms of collaboration types, the number of studies about actual locations (countries) with or without at least one author affiliation in the studied location. If a paper studied more than one location, we treated each location as a separate instance. This increased the denominators accordingly. 

We summarized the interventions studied by grouping the studies into three categories, that is, studies that modelled non-vaccination interventions, those that modelled vaccination in combination with other interventions, and those that modelled vaccination as a single intervention for comparison with other interventions. We also summarised the top two most studied intervention for each disease by counting the number of times each disease was studied per paper. 

For the disease studied, model characteristics (structure, dynamics, and spatial heterogeneity), and modelling practices (parametrization, validation, sensitivity analysis, data use and available, and code use and availability), we counted the number of studies per collaboration type and reported the results as percentages and fractions of the total. In counting the number of papers per disease studied and outcome measured, if a study had more than one outcome measured or disease, we treated each instance as unique and counted them separately. Hence, in such cases, the denominator of the reported fraction increased from the total studies we reported in our search results. 

To summarise the model outcomes, we stratified by the collaboration type and tallied the outcomes used within each group. We reported the top six most used outcomes by both collaboration types and compared the results between the two.

All analyses were perform in R version 4.3.0 ~\cite{R2023}.  The raw analysis of the results presented in the main text have been provided as a supplement (\nameref{S2_File}). We have also supplied as supplementary files a pdf of tables with the database of the included studies and extracted data (\nameref{S4_Table}). The R code and data for this analysis can be found in a public Github repository accessible at \url{https://github.com/jamesmbaazam/orv_modelling_review_epidemics}.


\section*{Results}
\subsection*{Study selection}
We retrieved a total of $12, 986$ bibliographic records from Scopus, PubMed, and Web of Science (Fig \ref{fig:fig1prismaflowchart}). Using Endnote and Rayyan, we identified and removed $7, 974$ duplicates, resulting in $5, 012$ unique records. We exported the unique records into Rayyan for screening in two stages. 


Stage one involved screening titles and abstracts in duplicate by the three reviewers. After this stage, $4, 211$ studies were excluded. At stage two, we screened the full text of the remaining studies, and this led to $549$ exclusions. 

After stage two, $252$ studies remained for the data extraction stage. Of the $252$ studies, $227$ were about human vaccine-preventable diseases and $25$ studies about foot-and-mouth disease (FMD). The FMD studies were not used in the main analysis but only for comparisons in the dedicated section for FMD.

\begin{figure}[h!]
	\includegraphics[scale=0.65]{figs/fig1_PRISMA_flowchart}
	\caption{\bf The PRISMA flow chart. Numbers described here include studies for both the human vaccine-preventable diseases and foot-and-mouth disease.}
	\label{fig:fig1prismaflowchart}
\end{figure}

\subsection*{Publications over time}
Overall, a few relevant papers were published between 1970-2005 $(4.0\%; 9/227)$, followed by a marked increase in publications until 2019 $(96.0\%; 218/227)$ (Fig \ref{publications_per_year}). 

\begin{figure}[!h]	
 \includegraphics[scale=0.70]{figs/fig2_publications_per_year.png}
	\caption{\bf Number of publications per year (1970-2019).}
	\label{publications_per_year}
\end{figure}

We first categorised the papers according to the unique combinations of author affiliation types (Table \ref{studies_per_author_affiliations_type}). 

Overall, papers with all authors from academic institution affiliations were the most common (56.8\%; 129/227). Papers with author affiliations from academic and governmental organizations were the second most common (24.2\%; 55/227), and followed by those from academic and NGO affiliations (7.5\%; 17/227). The least common were those from governmental and NGO affiliations (0.9\%; 2/227).

As explained earlier in the methods section, for the analyses moving forward, we grouped the author affiliation combinations into two collaboration types: purely academic and mixed. There were more purely academic collaborations (56.8\%; 129/227) than mixed collaborations (43.2\%; 98/227). 

\begin{table}[!h]
\centering
\caption{\bf Number of studies per unique combination of author affiliations (human diseases). Here, we also show the categorization of the author affiliation combinations into purely academic and mixed collaborations. Papers authored by purely academic collaborations have all authors being affiliated to academic institutions whereas those authored by mixed collaborations have authors being affiliated to a combination of academic institutions, government institutions, and NGOs or only one of the last two.}
\setlength\arrayrulewidth{1pt} 
\begin{tabular}{|l l c|}
\hline
\textbf{Collaboration type} & \textbf{Author affiliation combination} & \textbf{Number of publications} \\ \hline
Purely academic & academic only  & 129 \\ \hline
Mixed & academic + governmental   & 55 \\ \hline
Mixed & academic + NGO                 & 17  \\ \hline
Mixed & academic + governmental + NGO    & 14 \\ \hline
Mixed & governmental only                & 5 \\ \hline
Mixed & NGO only                       & 5  \\ \hline
Mixed & governmental + NGO               & 2 \\ \hline  \rowcolor{gray!20}
\textbf{Total} &  & \textbf{227} \\  \hline 
\end{tabular}
\label{studies_per_author_affiliations_type}
\end{table}

To investigate the changes in collaboration types over time, we calculated the number and proportion of studies per collaboration type per year (Fig \ref{studies_per_collab_type}). In the past seven years (2013-2019), there was an absolute increase in the number of papers by both collaboration types. However, in the same period, there was no increase in the relative proportion of publications per year of mixed collaborations (\nameref{S1_Fig}).

\begin{figure}[!h]
\includegraphics[scale=0.65]{figs/fig3_total_collabs_per_year_plot.png}
	\caption{\bf Total studies by collaboration type. The period from 1970-2005 has been lumped up due to the lack of publications. Academic collaborations refer papers with all authors affiliated to academic institutions whereas mixed collaborations include papers authored by a mixture of authors who are affiliated with academic institutions, government institutions, and/or NGOs. Mixed collaborations are represented by the turquoise bars and purely academic collaborations by the brown bars.}
	\label{studies_per_collab_type}
\end{figure}

\subsection*{Locations studied}
Overall, most of the papers were about actual geographic locations $(78.9\%; 195/247)$ as compared to hypothetical locations $(21.1\%; 52/247)$. Among the former, some studied a geographic location spanning more than one country but not classifiable as a continent $(9.7\%; 19/195)$. Moreover, among those $19$ studies, West Africa was the most studied $(47.4\%; 9/19)$, followed by the whole globe $(36.8\%; 7/19)$, Southeast Asia $(10.6\%; 2/19)$, and the Northern Hemisphere $(5.3\%; 1/19)$. 

When aggregated into continents, the Americas were studied the most $(36.4\%; 68/187)$, followed by Asia $(25.1\%;47/187)$, Africa $(24.6\%; 46/187)$, Europe $(13.4\%; 25/187)$, and Oceania $(0.5\%; 1/187)$.

When disaggregated into countries, the United States was the most studied $(21.6\%; 38/176)$, followed by China $(10.8\%; 19/176)$, Canada $(6.2\%; 11/176)$, and Sierra Leone $(5.7\%; 10/176)$.

\subsection*{Connection of authors to the location studied}
We investigated the connection of the authors to the location studied and found that, overall, there were more studies with at least one author connected to the studied location $(75.2\%; 118/157)$ than not $(24.8\%; 39/157)$. 

When stratified by collaboration types, mixed collaborations were more likely to have studies with at least one author in the location studied $(84.0\%; 63/75)$ compared with the purely academic collaborations $(67.1\%; 55/82)$. 

\subsection*{Diseases studied}
Overall, the number of studies per disease was disproportionately distributed (Table \ref{studies_per_disease_and_collaboration_type}). Influenza was the most studied $(57.4\%; 135/235)$, followed by Ebola $(14.5\%; 34/235)$, Dengue $(5.1\%; 12/236)$, and a tie between Cholera $(4.7\%; 11/235)$, and Measles $(4.7\%; 11/235)$. 

When the diseases were broken down in terms of which collaboration types studied them, there were clear differences in their distribution. Influenza, Dengue, and Measles were more studied by mixed collaborations whereas Ebola and Cholera were more studied by purely academic collaborations. 

\begin{table}[!h]
	\setlength\arrayrulewidth{1pt} 
	\centering
	\caption{\bf Number of studies per disease and collaboration type. Percentages are calculated from the row totals. The number of studies making up the percentages are shown in brackets. In counting the number of papers per disease studied, if a study was about more than one disease, we treated each instance as unique and counted them separately, leading to a total greater than the reported number of studies.}
	\begin{tabular}{|l c c c|}
		\hline
		\textbf{Disease}         & \textbf{Purely academic} & \textbf{Mixed} & \textbf{Total} \\ \hline
		Influenza                & 54.1\% (73)     & 45.9\% (62) & 135   \\ \hline
		Ebola                    & 70.6\% (24)     & 29.4\% (10) & 34    \\ \hline
		Dengue                   & 50.0\% (6)      & 50.0\% (6)  & 12    \\ \hline
		Cholera                  & 81.8\% (9)      & 18.2\% (2)  & 11    \\ \hline
		Measles                  & 36.4\% (4)      & 63.6\% (7)  & 11    \\ \hline
		Poliomyelitis            & 28.6\% (2)      & 71.4\% (5)  & 7     \\ \hline
		Tuberculosis             & 83.3\% (5)      & 16.7\% (1)  & 6     \\ \hline
		Varicella                & 50.0\% (2)      & 50.0\% (2)  & 4     \\ \hline
		Meningococcal meningitis & 33.3\% (1)      & 66.7\% (2)  & 3     \\ \hline
		Pertussis                & 50.0\% (1)      & 50.0\% (1)  & 2     \\ \hline
		Pneumococcal disease     & 50.0\% (1)      & 50.0\% (1)  & 2     \\ \hline
		Yellow fever             & 50.0\% (1)      & 50.0\% (1)  & 2     \\ \hline
		Hepatitis A             & 100.0\% (1)     & 0.0\% (0)   & 1     \\ \hline
		Rubella                  & 100.0\% (1)     & 0.0\% (0)   & 1     \\ \hline
		Typhoid                  & 100.0\% (1)     & 0.0\% (0)   & 1     \\ \hline
		Hepatitis B              & 0.0\% (0)       & 100.0\% (1) & 1     \\ \hline
		Malaria                  & 0.0\% (0)       & 100.0\% (1) & 1     \\ \hline
		Mumps                    & 0.0\% (0)       & 100.0\% (1) & 1    \\ \hline \rowcolor{gray!20}
		\textbf{Overall}			&	\textbf{56.2\% (132)}   			& \textbf{43.8\% (103)}   & \textbf{100\% (235)} \\
		\hline
	\end{tabular}
	\label{studies_per_disease_and_collaboration_type}
\end{table}

\subsection*{Intervention types}
There were more papers about non-vaccination interventions $(47.6\%; 108/227)$, followed by those that modelled vaccination in combination with other interventions or do-nothing counterfactuals $(41.0\%; 93/227)$, and those that modelled vaccination as a single intervention for side-by-side comparison with other non-vaccination interventions $(11.5\%; 26/227)$. 

We also tabulated the top 2 interventions studied per disease (Table \ref{top2_interventions_per_disease}).


\begin{table}
	\setlength\arrayrulewidth{1pt} 
	\centering
	\caption{\bf Top 2 most studied interventions per disease. We counted the unique number of times an intervention was studied per disease and reported the top two.}
		\begin{tabular}{| l | l |}
			\hline
			\textbf{Disease} & \textbf{Intervention modelled} \\ \hline
			Cholera & vaccination \\ \hline
			Cholera & hygiene \\ \hline
			Dengue & vaccination \\ \hline
			Dengue & larvicides \\ \hline
			Ebola & isolation \\ \hline
			Ebola & safe burial \\ \hline
			Hepatitis a & vaccination \\ \hline
			Hepatitis b & vaccination \\ \hline
			Influenza & vaccination \\ \hline
			Influenza & school closure \\ \hline
			Malaria & drugs \\ \hline
			Malaria & treatment \\ \hline
			Measles & vaccination \\ \hline
			Measles & behavioural change \\ \hline
			Meningococcal meningitis & vaccination \\ \hline
			Meningococcal meningitis & PPE \\ \hline
			Pertussis & vaccination \\ \hline
			Pertussis & contact tracing \\ \hline
			Pneumococcal disease & treatment \\ \hline
			Poliomyelitis & vaccination \\ \hline
			Poliomyelitis & school closure \\ \hline
			Rubella & vaccination \\ \hline
			Tuberculosis & treatment \\ \hline
			Tuberculosis & vaccination \\ \hline
			Typhoid & screening \\ \hline
			Varicella & vaccination \\ \hline
			Varicella & isolation \\ \hline
			Yellow fever & vaccination \\ \hline
		\end{tabular}
			\label{top2_interventions_per_disease}
	\end{table} 


\subsection*{Model structure, spatial heterogeneity, and model dynamics}
There were more compartmental models $(78.9\%; 179/227)$ than agent-based models $(19.8\%; 45/227)$ with no clear difference in preference between the two collaboration types. 

Approximately a third of the papers included spatial heterogeneity $(28.6\%; 65/227)$ with no clear difference between the two collaboration types. 

Deterministic models were the most common $(63.4\%; 144/227)$ compared to stochastic $(30.4\%; 69/227)$ and hybrid models $(6.2\%; 14/227)$, that is models with both deterministic and stochastic components. Mixed collaborations were more likely to use stochastic models $(39.8\%; 39/100)$ than purely academic collaborations $(23.3\%; 30/128)$.

\subsection*{Outcomes measured}
We counted the unique number of times an outcome was studied by each collaboration type (Table \ref{top 6 outcomes studied by collab types}). Final epidemic size was the top outcome of interest in both groups. The top 6 outcomes were common between both groups except for intervention cost, which was more of interest to purely academic collaborations but not to mixed collaborations. On the other hand, number of hospitalizations was more of interest to mixed collaborations than purely academic collaborations. 


\begin{table}[h!]
	 \caption{\textbf{Top 6 outcomes studied per collaboration type. Percentages are calculated from the total of studies within each collaboration type. Actual numbers are provided in brackets.}}
	 \centering
	 \begin{tabular}{| l | l | l |}\hline
	 	\textbf{Collaboration type} & \textbf{Outcome measured} & \textbf{number of studies} \\ \hline
	 	Purely academic & final epidemic size & 22.0\%  (55)\\ \hline
	 	 & attack rate & 11.6\%  (29)\\ \hline
	 	 & timing of peak & 8.0\%  (20)\\ \hline
	 	 & cost & 7.2\%  (18)\\ \hline
	 	 & outbreak duration and timing & 6.0\%  (15)\\ \hline
	 	 & cases averted & 4.8\%  (12)\\ \hline
	 	Mixed & final epidemic size & 14.4\%  (31)\\ \hline
	 	 & attack rate & 13.4\%  (29)\\ \hline
	 	 & cases averted & 10.2\%  (22)\\ \hline
	 	 & timing of peak & 7.,4\%  (16)\\ \hline
	 	 & outbreak duration and timing & 6.0\%  (13)\\ \hline
	 	 & hospitalizations & 4.2\%   (9)\\ \hline
 	\end{tabular}
 	\label{top 6 outcomes studied by collab types}
 	\end{table}

\subsection*{Model parametrization and validation}
The top three most commonly used parametrization methods, that is, how model parameter values were obtained, included: combining literature sources and expert opinion/assumptions, literature sources and fitting to data, and literature sources only (Table \ref{model_parametrization_results}). 

The most common parametrization method among mixed collaborations was the combination of literature sources and fitting $(28.6 \%; 28/98)$, whereas the combination of literature and expert opinion was the most common among purely academic collaborations $(27.1\%; 35/129)$. 

\begin{table}[!h]
\setlength\arrayrulewidth{1pt} 
\centering
\caption{\bf Model parametrization methods. We define model parametrization as the method of determining the parameter values for the model. In the table, ``Literature'' means the model's parameters were obtained from literature sources. ``Expert opinion'' means the values were assumed in consultation with experts of the field. ``Fitted'' means the model’s parameters were obtained through some form of mathematical or statistical fitting to a time series of data. }
\begin{adjustwidth}{-2.10in}{0in}
\begin{tabular}{| p{0.17\textwidth}  p{0.14\textwidth}  p{0.14\textwidth}  p{0.12\textwidth}  p{0.13\textwidth}  p{0.13\textwidth}  p{0.12\textwidth}  p{0.1\textwidth}  p{0.07\textwidth} |} \hline 
\textbf{Collaboration type} & \textbf{Literature and expert opinion} & \textbf{Literature and fitted} & \textbf{Literature} &  \textbf{Literature, expert opinion, and fitted} & \textbf{Expert opinion} & \textbf{Fitted} & \textbf{Expert opinion and fitted} & \textbf{Total} \\ \hline
Academic & 27.1\% (35) & 21.7\% (28) & 17.8\% (23) & 10.1\% (13) & 14.0\% (18)  & 7.0\% (9) & 2.3\% (3) & 129 \\ \hline
Mixed & 24.5\% (24) & 28.6\% (28) & 14.3\% (14) & 19.4\% (19) & 7.1\% (7) & 5.1\% (5) & 1.0\% (1) & 98 \\ \hline \rowcolor{gray!20}
Overall & 26.3\% (59) & 24.7\% (56) & 16.3\% (37) & 14.1\% (32) & 11.0\% (25) & 6.2\% (14) & 1.8\% (4) & 227 \\ \hline 
\end{tabular}
\end{adjustwidth}
\label{model_parametrization_results}
\end{table}

We defined model validation as the method by which the model's performance was measured. Four categories of model validation were established for the purpose of this review. In Table \ref{model_validation_results}, we present the results. If the model was not validated with observed data or another model's output, we classified its validation as ``none''.  ``Data'' means the model's output was compared to independently observed data. ``Another model’s output'' means the model's output was compared to an independent model's output. Some studies also used data and another model's output. We classified these as ``data and another model".


Most studies were classified as none $(63.2\%; 144/227)$. Approximately a third used data to validate their models $(34.6\%; 79/227)$ (Table \ref{model_validation_results}). 


In terms of differences between the collaboration types, mixed collaborations were more likely to validate their model with data or the output of an independent model. 

\begin{table}[!h]
	\centering
	\setlength\arrayrulewidth{1pt} 
	\caption{\bf Model validation methods.}
	\begin{adjustwidth}{-0.00in}{0in}
		\begin{tabular}{| p{0.15\textwidth}  p{0.13\textwidth} p{0.13\textwidth} p{0.13\textwidth} p{0.13\textwidth} p{0.12\textwidth}|}
			\hline
			\textbf{Collaboration type} & \textbf{None} & \textbf{Data} & \textbf{Another model's output} & \textbf{Data and another model} & \textbf{Total} \\ \hline
			Academic & 71.3\% (92) & 27.9\% (36) & 0.8\% (1) & 0.0\% (0) & 129 \\ \hline
			Mixed & 53.1\% (52) & 42.9\% (42) & 3.1\% (3) & 1.0\% (1) & 98 \\ \hline \rowcolor{gray!20}
			Overall & 63.4\% (144) & 34.4\% (79) & 1.8\% (4) & 0.4\% (1) & 227\\ \hline
		\end{tabular}
	\end{adjustwidth}
	\label{model_validation_results}
\end{table}


\subsection*{Data and model simulation code}
More than half of the papers used datasets collected independent of the study for either the model parametrization or validation process $(55.5\%; 126/227)$. These papers were split equally between the two collaboration types. 

The use of accessible data was, however, different between the two groups. Purely academic collaborations were more likely to use data that could be accessed in the public domain $(82.5\%; 52/63)$ compared to mixed collaborations $(58.7\%; 37/63)$.  

Few papers provided access to the model simulation code $(1.7\%; 4/227)$. Here, if a paper indicated that the authors could be contacted for the code, it was deemed as inaccessible due to the many hurdles with getting the code in time. Additionally, some papers reported the computer application/software/program/package used (R, Python, C++, Matlab, and so forth) but we did not collect that information. 

\subsection*{Patterns in the foot and mouth disease (FMD) literature}
We included $25$ foot and mouth disease modelling studies for comparison with the human disease literature. Due to the small number of studies, the absolute differences between the two collaboration types were generally not large enough to be considered (\nameref{S2_File}), hence, we report on the aggregated patterns. 

Slightly more than half of the $25$ studies were authored by mixed collaborations $(56.0\%; 14/25)$. In terms of how connected the authors were to the locations studied, almost all the papers had at least one author affiliated to an institution in the location studied $(92.0\%; 23/25)$. 

Overall, vaccination was modelled as a single intervention for comparison in more than half of the studies $(56.0\%; 14/25)$, followed by vaccination in combination with other interventions $(28.0\%; 7/25)$, and no vaccination $(16.0\%; 4/25)$.  


In general, the FMD models had more agent-based $(76.0\%; 19/25)$ and spatially explicit structure $(72.0\%; 18/25)$, largely used stochastic dynamics $(56.0\%; 14/25)$, and performed more sensitivity analyses $(56.0\%; 14/25)$. 

Outbreak duration and timing, final epidemic size, and intervention costs were the top three outcomes of interest overall. 


In terms of model parametrization, the most common method was the combined use of literature sources and expert opinion $(28.0\%; 7/25)$, followed by fitting to data only $(20.0\%; 5/25)$, and the combined use of literature sources, expert opinion, and fitting to data $(16.0\%; 4/25)$. In terms of model validation, most of the FMD models were not compared to observed data or the output of independent models $(72.0\%; 18/25)$. 

\section*{Discussion}
For the period $1970-2019$, the outbreak response intervention impact modelling literature for human vaccine-preventable diseases was dominated by purely academic collaborations. This collaboration type, which we defined as papers with all authors affiliated to academic institutions, formed over $56\%$ of the literature. Both purely academic and mixed collaborations increased in absolute numbers in the last seven years of the review period (2013-2019). Regarding modelling practices between the two collaboration types, mixed collaborations were more likely to: (i) include authors who were affiliated to an institutions in the location studied, (ii) use more complex modelling practices including stochastic model dynamics, parametrization methods involving a combination of literature sources, expert opinion/assumptions, and fitting to data, and validate their models with data collected independent of the study. Even though this review was about human vaccine-preventable diseases, only 52.5\% of the studies modelled vaccination in some form. Influenza was disproportionately the most studied disease, followed by Ebola, and Dengue. Final epidemic size and attack rate were a commonly preferred modelling outcome of interest. Lastly, even though all the studies conducted simulation studies, code availability was rare as only $1.8\%$ of the studies $(4/227)$ made them readily accessible.


There were several differences in models and modelling practices/approaches between the human disease literature and foot and mouth disease (FMD). Mixed collaborations dominated the FMD literature and almost all the papers had an author in the location studied. Furthermore, most of the FMD models and modelling practices were more complex involving the use of spatial, stochastic, agent-based models. However, the FMD models were less likely to be validated with real world data.

We quantified the presence of mixed collaborations in outbreak response modelling between $1970$ and $2019$ (Fig \ref{studies_per_collab_type}). Our results show an absolute increase in the number of papers published by mixed collaborations during the period. Mixed or interdisciplinary collaborations have been reported to be strongly associated with research impact and translation to decision-making \cite{Deelstra2003}. We, however, did not measure the impact of mixed collaborations in outbreak response decision-making and therefore recommend that future studies consider pursuing this. Outbreak response, which is broadly an operational field, should ideally have modelling groups/collaborations that impact decision-making. 


The increase in mixed collaborations could suggest an increase in the uptake or recognition of modelling by decision-makers in governmental and non-governmental organizations as an outbreak response decision-making tool. There are examples of the commissioning of modelling by organisations such as the US Centers for Disease Control and Prevention (CDC) and the World Health Organization (WHO) to support decision-making during past outbreaks of Influenza, Ebola, Zika, and Dengue \cite{Muscatello2017}. However, research that measures the direct impact and contributions of such collaborations to decision-making remains lacking in the literature and calls for future research \cite{Muscatello2017}. 

The inclusion of local experts in outbreak response modelling teams helps with more tailored problem-solving and decision-making and better reception of the decisions made \cite{Abramowitz2015}. In that regard, mathematical modelling collaborations involving local experts or, in this review, locally affiliated co-authors are an important first step towards achieving this. We found that most of the human disease studies had authors with an institutional affiliation in the location studied. We observed the same pattern for FMD albeit at a much higher percentage. When the human disease data was disaggregated, the results showed that mixed collaborations had a much higher percentage. 

We found some commonalities and differences in the choice of model structure and dynamics between the two collaboration types in the human disease literature. Mixed collaborations were more likely to use agent-based model structures and model validation methods like comparing model outputs to observed data. These are often difficult to implement in practice and tend to lead to complex outcomes. We are not making any value judgements with regards to complexity but are only highlighting these differences that might require further investigation. Moreover, it is common to model an outbreak using alternative model choices and assumptions depending on the question being answered \cite{Basu2013}. However, the results must always be interpreted with cognisance of the limitations/assumptions of the model.  The use of more complex models and practices by mixed collaborations is likely due to the fact that often, real world public health policy-related decision-making is operational, requiring finer details in models and approaches to answer the questions posed in a practical way. Our definition of mixed collaborations meant that it may have involved decision-makers. It is, therefore, likely that their need for practical solutions could have influenced higher levels of model complexity. 

The FMD models were generally more complex than the human disease models. This is not surprising because the nature of FMD spread often requires the inclusion of farm structure, farm connectivity, and demographics to capture the disease's dynamics accurately and to capture the complex nature of the responses to outbreaks in terms of movement control and depopulations of farms \cite{Kinsley2018}. These levels of detail and complexity are often required in human disease outbreak models, but we observed a more frequent use among the FMD studies. Future studies designed to explain the differences in modelling practices of human outbreak response modelling groups might help to explain what we have observed in this review.

A little over half of the human disease papers used observed data for parametrization or validation. Additionally, only 4 studies shared their code in an easy to access form. Owing to this, it might be difficult to reproduce some of the results in these outbreak response modelling studies. We recognise that data sharing in public health raises a lot of debate regarding privacy and intellectual property, and often, authors are hindered by institutional data sharing policies \cite{Kim2016}. We, however, recommend that data and code be shared where possible to promote open science practices that help advance the field.  The FMD models were generally not validated with observed data. This is most likely due to the lack of data on FMD outbreaks as most areas in the world are free of FMD outbreaks. The lack of data seems to have constrained FMD outbreak model validation and might serve as an opportunity to use data-free model validation techniques. However, these techniques were not captured in this review.


This review had several limitations. First, outbreak response models and analyses are not always published in peer-reviewed journals, but this systematic review only focused on peer-reviewed articles. It is, therefore, possible that some relevant studies were missed by our search strategy. Second, we used the author list and affiliations to classify studies as either purely academic or mixed. However, this could cause some mixed collaborations to be misclassified as purely academic, especially in cases where non-academics contributed to papers classified as purely academic but were not included on the author list. It is, however, standard practice to include individuals who contributed substantially to a piece of scientific writing, hence, if that was not done for a paper, it could imply that the level of interaction was not high enough to warrant the credit of authorship. Third, in the absence of an explicit measure of contribution of mathematical modelling to outbreak response decision-making, we used mixed collaborations as a proxy. Thus, we may be under-estimating the number of mixed collaborations in the literature. Fourth, we only surveyed the literature on a specific study design – mechanistic models. We excluded statistical models and other computational models, which are not mechanistic. Hence, the results of this systematic review should only be interpreted in the context of the mechanistic modelling landscape. Furthermore, it is also possible that some purely academic collaborations contribute to decision-making whereas some mixed collaborations are purely an academic exercise. Also, we  conducted our database searches in January 2020 and therefore do not reflect the literature, or any changes in practice, associated with the COVID-19 pandemic. This study, however, provides a baseline for comparing practices before and after the COVID-19 pandemic. Lastly, by only including papers published in English, we most certainly missed papers published in other languages.  

Numerous factors could explain the patterns we have observed in this review, and we would recommend future studies that will use appropriate study designs, for example, interviews of modelling groups and public health decision-makers, to explain why certain model choices and modelling practices were made by the collaboration types. Future studies should investigate when modelling results directly impacted decision-making and what determined that to identify best practices that will strengthen the link between modelling and decision-making in the future. We expect that collaboration between academia, decision-makers, and local experts will enhance decision-making by accounting for aspects of policy and decision-making that might be overlooked in studies conducted mainly as a theoretical exercise. 

\subsection*{Other information}
A protocol following the PRISMA guidelines for systematic review protocols and outlining the procedures for this systematic review was registered on PROSPERO with registration number CRD42020160803 and published through a peer-reviewed process~\cite{Azam2020}. 

\section*{Supporting information}

\paragraph*{S1 File}
\label{S1_File}
{\bf Search strings and results, data items extracted, and questionnaire for data extraction.} 

\paragraph*{S1 Fig}
\label{S1_Fig}
{\bf Collaboration patterns in time (proportions per year).}

\paragraph*{S2 File}
\label{S2_File}
{\bf Analysis of extracted data.} 

\paragraph*{S3 Table}
\label{S3_Table}
{\bf PRISMA checklist.} 

\paragraph*{S4 Table}
\label{S4_Table}
{\bf Database of included studies and extracted data per paper.} 

%\section*{Acknowledgments}

% Use the PLoS provided BiBTeX style
\bibliography{references.bib}
\bibliographystyle{vancouver}
\nolinenumbers
\end{document}

